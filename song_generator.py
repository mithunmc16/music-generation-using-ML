"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""

This code is written as part of COMP8755- Individual Computing Project

This code is for preprocessing and training the LSTM network

The songs are first parsed and the notes of different instruments are procesed to train and mdh5 files for music generation.


@Author:
Mithun
u6849970

@ Supervisor:
Professor Nick Birbillis

"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
import pickle
import numpy
from music21 import instrument, note, stream, chord
from keras.models import *
from keras.layers import *

"""
This fucntion is to prepare the sequencce if the song based on the notes and pitch

"""
def prepare_sequences(notes, pitchnames, n_vocab):
    """
	We map the integers and notes in the notes file to actial notes in music

"""
    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))

    sequence_length = 100
    network_input = []
    
    for i in range(0, len(notes) - sequence_length, 1):
        """
	for each note, we process then so that they can be normalised
"""
        sequence_in = notes[i:i + sequence_length]
        
        network_input.append([note_to_int[char] for char in sequence_in])
        

    n_patterns = len(network_input)
    """
We reshape the input using numpy so that it becomes comatinble with the LSTM layers
"""
    
    normalized_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))
    normalized_input = normalized_input / float(n_vocab)

    return (network_input, normalized_input)

"""
we need to create the network back so that we can predict the next set of notes for generating music
"""

def create_network(network_input, n_vocab):
    model = Sequential()
    """
	Creating a sequential model
	
"""
    model.add(LSTM(
        512,
        input_shape=(network_input.shape[1], network_input.shape[2]),
        return_sequences=True
    ))
    """
	We add the various factors sucha s the sensity, network input and output
"""
    model.add(Dropout(0.3))
    model.add(LSTM(512, return_sequences=True))
    model.add(Dropout(0.3))
    model.add(LSTM(512))
    model.add(Dense(256))
    model.add(Dropout(0.3))
    model.add(Dense(n_vocab))
    model.add(Activation('softmax'))
    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')

    """
   We load the weight geberated from the training and load it to the model.
   """
    
    model.load_weights('weights.hdf5')

    return model

"""
This function generates the notes in a sequential pattern which is then converted to MIDI file
we pick a random sequence from the input and use it as a starting point for generation
"""
def generate_notes(model, network_input, pitchnames, n_vocab):
    """
	Random number for prediction
	"""
    start = numpy.random.randint(0, len(network_input)-1)
# the integer in notes is converted to a musical note
    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))

    pattern = network_input[start]
    prediction_output = []

    for note_index in range(500):
        """
	We generate a total of 500 notes, 
"""
        prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))
        prediction_input = prediction_input / float(n_vocab)
        """
		#from the prediction input, we use the keras libary for the same
"""
        prediction = model.predict(prediction_input, verbose=0)

        index = numpy.argmax(prediction)
        result = int_to_note[index]
        prediction_output.append(result)
        """
		The pattern will contain the musical notes which is stored as an array
"""
        pattern.append(index)
        pattern = pattern[1:len(pattern)]

    return prediction_output

"""
Generating the Midi file from prediction
"""
def create_midi(prediction_output):
    offset = 0
    output_notes = []
    """
    # create note and chord objects based on the values generated by the model
	
"""
    for pattern in prediction_output:
        """
		if the pattern in the prediction is a number then it is a chord.
		"""
        if ('.' in pattern) or pattern.isdigit():
            """
		# we split the note at the '.', we split it at that point.
        """
            notes_in_chord = pattern.split('.')
            notes = []
            for current_note in notes_in_chord:
                """
			# all the chords are processed and new chord is generated
            """
                new_note = note.Note(int(current_note))
                new_note.storedInstrument = instrument.Piano()
                notes.append(new_note)
            new_chord = chord.Chord(notes)
            new_chord.offset = offset
            output_notes.append(new_chord)
            """
		If the pattern is a rest 
"""		
        elif pattern == 'rest':
            new_note = note.Rest()
            new_note.offset = offset
            """
			#We create the songs with piano only
"""
            new_note.storedInstrument = instrument.Piano()
            output_notes.append(new_note)
            """	
        if pattern is a note
"""
        else:
            new_note = note.Note(pattern)
            new_note.offset = offset
            """
			#We create the songs with piano only
"""
            new_note.storedInstrument = instrument.Piano()
            output_notes.append(new_note)
            """
The offset is increased for each iteration so that the notes are not stacked
"""
        offset += 0.25

    midi_stream = stream.Stream(output_notes)

    midi_stream.write('midi', fp='test_output.mid')


if __name__ == '__main__':
     
   
    with open('data\music', 'rb') as fp:
        notes = pickle.load(fp)
        """
All the items in the notes are sorted
"""
    pitchnames = sorted(set(item for item in notes))
  
    n_vocab = len(set(notes))
    """
	Calling function to prepare sequences
	"""
    network_input, normalized_input = prepare_sequences(notes, pitchnames, n_vocab)
    """
	Calling function to create network
	"""
    model = create_network(normalized_input, n_vocab)
    """
	Calling function to create MIDI
	"""
    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)
    """
	Calling function to create MIDI
	"""
    create_midi(prediction_output)
